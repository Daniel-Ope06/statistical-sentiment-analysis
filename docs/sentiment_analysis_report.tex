\documentclass[12pt, a4paper]{article}

% --- Font and Language Setup (Requires XeLaTeX compiler) ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{carlito}
\renewcommand{\familydefault}{\sfdefault}

% --- Packages ---
\usepackage{geometry}
\geometry{top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm} % Standard academic margins
\usepackage{graphicx}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{listings}

% --- Python Code Formatting Setup ---
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}
\renewcommand{\lstlistingname}{Code Snippet}

% --- Document Info ---
\title{
    \Large \textbf{ITNPAI3: AI for NLP} \\
    \vspace{0.5cm}
    \LARGE \textbf{Sentiment Analysis of Twitter Data} \\
    \vspace{0.25cm}
    \large A Comparative Evaluation of Naive Bayes and Logistic Regression across Bag-of-Words and TF-IDF Representations
}
\author{Student ID: 3539054}
\date{February 26, 2026}

\begin{document}

\maketitle

\begin{abstract}
This report explores how to build a machine learning model capable of automatically classifying the sentiment of tweets as Positive, Negative, or Neutral. Before training the models, the raw text was cleaned and standardised. This included a custom "negation handling" step, which links words like "not" to the word that follows it (for example, turning "not good" into "not\_good") so the model correctly understands the true meaning of the sentence. The cleaned text was then converted into mathematical formats using two different methods: Bag-of-Words and TF-IDF. Two statistical classifiers, Naive Bayes and Logistic Regression, were trained and compared to determine which method could best identify human emotion. The results show that Logistic Regression paired with TF-IDF was the most effective approach, achieving an overall accuracy of 69.2\%.
\end{abstract}

\section{Data Preprocessing}

\quad Raw tweets contain significant noise and stylistic variations that can confuse machine learning algorithms. The first preprocessing step was converting all text to lowercase. While this removes the emotional intensity often conveyed through capital letters (e.g., "HATE" versus "hate"), it was a necessary trade-off for statistical models. Without lowercasing, models using Bag-of-Words or TF-IDF treat "Bad", "bad", and "BAD" as three entirely separate mathematical features. Lowercasing consolidates these variations, preventing feature fragmentation and preserving the vocabulary limit.

\vspace{0.5cm}

Next, regular expressions (Regex) were used to remove URLs, user mentions, and hashtags, as these rarely contribute to the underlying sentiment. However, because social media users frequently rely on punctuation to express strong feelings, multiple exclamation marks or asterisks (often used to mask profanity) were explicitly translated into readable text tokens (e.g., \texttt{exclamationmark}) before the remaining punctuation was stripped away.

\noindent\begin{minipage}{\textwidth}
\begin{lstlisting}[language=Python, caption=Regex logic for noise removal and punctuation preservation]
# Convert to lowercase
text = text.lower()

# Remove platform-specific noise (URLs, user mentions, hashtag symbols)
text = re.sub(r"http\S+|www\S+|https\S+", '', text, flags=re.MULTILINE)
text = re.sub(r'\@\w+', '', text)
text = re.sub(r'\#', '', text)

# Preserve sentiment-heavy characters by converting them to text tokens
text = re.sub(r'\*{2,}', ' censoredswear ', text)
text = re.sub(r'!+', ' exclamationmark ', text)
text = re.sub(r'\?+', ' questionmark ', text)
\end{lstlisting}
\end{minipage}

\vspace{0.5cm}

Finally, the \texttt{spaCy} natural language processing library was utilised to reduce words to their base dictionary form (lemmatisation) and remove common "stop words" to reduce data sparsity. Crucially, sentiment-altering words such as "not", "no", and "never" were retained. A custom negation handler was implemented to link these negations directly to the subsequent word. For instance, the phrase "not good" was transformed into \texttt{not\_good}. This ensures the model treats the negated phrase as a distinct, negative feature rather than misinterpreting "good" as a purely positive signal

\vspace{0.5cm}

\noindent\begin{minipage}{\textwidth}
\begin{lstlisting}[language=Python, caption=Custom negation handler linking modifiers to subsequent words]
# Flag the subsequent token for negation prefixing
if lemma in ["not", "no", "never", "cannot"]:
    negate_next = True
    # Append immediately to preserve if it is the final token
    tokens.append(lemma)
    continue

# Apply negation prefix by combining with the previous negation term
if negate_next:
    if tokens:  # Safety check to ensure the token list is not empty
        prev_negation = tokens.pop()
        lemma = f"{prev_negation}_{lemma}"
    negate_next = False
\end{lstlisting}
\end{minipage}

\begin{table}[h!]
    \centering
    \renewcommand{\arraystretch}{1.5}
    \begin{tabular}{|p{0.45\textwidth}|p{0.45\textwidth}|}
        \hline
        \textbf{Raw Tweet} & \textbf{Preprocessed Tweet} \\ \hline
        Sooo SAD I will miss you here in San Diego!!! & sooo sad miss san diego exclamationmark \\ \hline
        Sons of ****, why couldn`t they put them on the releases we already bought & son censoredswear release buy \\ \hline
        you can ride one, you can catch one, but its not summer til you pop open one & ride catch but not\_summer til pop open \\ \hline
    \end{tabular}
    \caption{Examples of raw text transformed by the custom preprocessing and negation pipeline.}
    \label{tab:preprocessing_examples}
\end{table}

\newpage

\section{Feature Representation}

\quad Because machine learning algorithms cannot process raw text, the preprocessed tweets had to be converted into numerical formats. This project evaluated two different mathematical representations: Bag-of-Words (BoW) and Term Frequency-Inverse Document Frequency (TF-IDF).

\vspace{0.5cm}

The Bag-of-Words approach converts text into a simple matrix where each column represents a unique word, and the values represent how many times that word appears in a specific tweet. While this method is straightforward, it treats all words as equally important. In human language, this is rarely true; highly frequent but emotionally neutral words can mathematically overshadow rare but highly emotional words.

\vspace{0.5cm}

To address this limitation, the TF-IDF method was also evaluated. TF-IDF does not just count how often a word appears in a single tweet; it scales that count based on how often the word appears across the entire dataset. If a word is extremely common everywhere, its mathematical weight is penalised. If a word is rare overall but appears in a specific tweet, its weight is heavily boosted. Theoretically, TF-IDF is better suited for capturing sentiment because human emotion is often conveyed through distinct, specialised words rather than common vocabulary.

\vspace{0.5cm}

For both methods, the feature matrix was strictly limited to the top 10,000 most frequent words. This limit prevents the dataset from becoming overwhelmed by rare misspellings, reducing noise and preventing the models from overfitting. How these two representations ultimately interact with the specific learning mechanics of Naive Bayes and Logistic Regression is detailed in the following section.

\section{Model Training \& Evaluation (Task 3)}
% Discuss Hyperparameter tuning (C=10.0) and Naive Bayes vs Log Reg.

\section{Error Analysis \& Diagnostics (Task 4)}
% Insert your Confusion Matrix and Feature Importance discussion here.

\section{Conclusion}
% Final reflections.

\end{document}